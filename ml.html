<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link data-next-font="" rel="preconnect" href="/" crossorigin="anonymous"/><link rel="preload" href="/_next/static/css/f1431a11044d3e28.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f1431a11044d3e28.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/_next/static/chunks/webpack-3d79c14ccb9ae0b4.js" defer=""></script><script src="/_next/static/chunks/framework-305cb810cde7afac.js" defer=""></script><script src="/_next/static/chunks/main-1e819d43c82e61a4.js" defer=""></script><script src="/_next/static/chunks/pages/_app-cc4af0cbd72d930f.js" defer=""></script><script src="/_next/static/chunks/c16184b3-1754bfa260bbde28.js" defer=""></script><script src="/_next/static/chunks/603-9686efb8fc297326.js" defer=""></script><script src="/_next/static/chunks/pages/ml-b1f0bd9645f32e90.js" defer=""></script><script src="/_next/static/-alH5WFx6uSTWWPfIdEA9/_buildManifest.js" defer=""></script><script src="/_next/static/-alH5WFx6uSTWWPfIdEA9/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><header><a href="/about">about</a><a href="/blog">blog</a><a href="/read">read</a><a href="/run">run</a><a href="/c">c</a><a href="/guidos/book/index.html" target="_blank" rel="noopener noreferrer">os</a><a style="text-decoration:underline" href="/ml">ml</a></header><div class="box helper-icons"><a href="/feed.xml"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="rss" class="svg-inline--fa fa-rss " role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 64C0 46.3 14.3 32 32 32c229.8 0 416 186.2 416 416c0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96C14.3 96 0 81.7 0 64zM0 416a64 64 0 1 1 128 0A64 64 0 1 1 0 416zM32 160c159.1 0 288 128.9 288 288c0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224c-17.7 0-32-14.3-32-32s14.3-32 32-32z"></path></svg></a><a><svg style="position:relative;top:2px" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 384 512"><path d="M297.2 248.9C311.6 228.3 320 203.2 320 176c0-70.7-57.3-128-128-128S64 105.3 64 176c0 27.2 8.4 52.3 22.8 72.9c3.7 5.3 8.1 11.3 12.8 17.7l0 0c12.9 17.7 28.3 38.9 39.8 59.8c10.4 19 15.7 38.8 18.3 57.5H109c-2.2-12-5.9-23.7-11.8-34.5c-9.9-18-22.2-34.9-34.5-51.8l0 0 0 0c-5.2-7.1-10.4-14.2-15.4-21.4C27.6 247.9 16 213.3 16 176C16 78.8 94.8 0 192 0s176 78.8 176 176c0 37.3-11.6 71.9-31.4 100.3c-5 7.2-10.2 14.3-15.4 21.4l0 0 0 0c-12.3 16.8-24.6 33.7-34.5 51.8c-5.9 10.8-9.6 22.5-11.8 34.5H226.4c2.6-18.7 7.9-38.6 18.3-57.5c11.5-20.9 26.9-42.1 39.8-59.8l0 0 0 0 0 0c4.7-6.4 9-12.4 12.7-17.7zM192 128c-26.5 0-48 21.5-48 48c0 8.8-7.2 16-16 16s-16-7.2-16-16c0-44.2 35.8-80 80-80c8.8 0 16 7.2 16 16s-7.2 16-16 16zm0 384c-44.2 0-80-35.8-80-80V416H272v16c0 44.2-35.8 80-80 80z"></path></svg></a></div><main><div class="content"><nav class="toc"><ol class="toc-level toc-level-1"><li class="toc-item toc-item-h1"><a class="toc-link toc-link-h1" href="#references">References</a></li></ol></nav>
<p>(<a href="http://arxiv.org/abs/1912.05911">Schmidt, 2019</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2112.04426">Borgeaud et al., 2021</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2101.00027">Gao et al., 2020</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2105.14103">Zhai et al., 2021</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2001.02320">Chukewad et al., 2020</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1709.07871">Perez et al., 2017</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2212.06817">Brohan et al., 2022</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1807.00412">Kendall et al., 2018</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2012.14905">Kirsch &amp; Schmidhuber, 2022</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2208.07860">Smith et al., 2022</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2301.04104">Hafner et al., 2023</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2301.04655">Gozalo-Brizuela &amp; Garrido-Merchan, 2023</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2006.04182">Millidge et al., 2020</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2203.02155">Ouyang et al., 2022</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1706.03762">Vaswani et al., 2017</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1912.01603">Hafner et al., 2020</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2212.13345">Hinton, 2022</a>)<!-- -->
<!-- -->(<a href="#">Solomitckii et al., 2016</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2106.09685">Hu et al., 2021</a>)<!-- -->
<!-- -->(<a href="http://bair.berkeley.edu/blog/2023/04/03/koala/">Seita &amp; Song, Accessed: 2023</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2010.11929">Dosovitskiy et al., 2021</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2407.08790">Birhane &amp; McGann, 2024</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2501.19393">Muennighoff et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2501.12948">DeepSeek-AI et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2305.11206">Zhou et al., 2023</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1511.07916">Cho, 2015</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/1510.00726">Goldberg, 2015</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2502.18394">Fein-Ashley, 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2503.01307">Gandhi et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2503.02113">Wilson, 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2503.10622">Zhu et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2504.20879">Singh et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2505.05522">Darlow et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2505.03335">Zhao et al., 2025</a>)<!-- -->
<!-- -->(<a href="#">Jaghouar et al., </a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2505.06120">Laban et al., 2025</a>)<!-- -->
<!-- -->(<a href="http://arxiv.org/abs/2505.12540">Jha et al., 2025</a>)</p>
<h1 id="references">References</h1>
<hr/>
<p class="reference-item">Schmidt, R.M. (2019). <em>Recurrent Neural Networks (RNNs): A gentle Introduction and Overview. </em><a href="http://arxiv.org/abs/1912.05911">http://arxiv.org/abs/1912.05911</a></p>
<p class="reference-item">Borgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Rutherford, E., Millican, K., Driessche, G.v.d., Lespiau, J., Damoc, B., Clark, A., Casas, D.d.L., Guy, A., Menick, J., Ring, R., Hennigan, T., Huang, S., Maggiore, L., Jones, C., Cassirer, A., Brock, A., Paganini, M., Irving, G., Vinyals, O., Osindero, S., Simonyan, K., Rae, J.W., Elsen, E. &amp; Sifre, L. (2021). <em>Improving language models by retrieving from trillions of tokens. </em><a href="http://arxiv.org/abs/2112.04426">http://arxiv.org/abs/2112.04426</a></p>
<p class="reference-item">Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S. &amp; Leahy, C. (2020). <em>The Pile: An 800GB Dataset of Diverse Text for Language Modeling. </em><a href="http://arxiv.org/abs/2101.00027">http://arxiv.org/abs/2101.00027</a></p>
<p class="reference-item">Zhai, S., Talbott, W., Srivastava, N., Huang, C., Goh, H., Zhang, R. &amp; Susskind, J. (2021). <em>An Attention Free Transformer. </em><a href="http://arxiv.org/abs/2105.14103">http://arxiv.org/abs/2105.14103</a></p>
<p class="reference-item">Chukewad, Y.M., James, J., Singh, A. &amp; Fuller, S. (2020). <em>RoboFly: An insect-sized robot with simplified fabrication that is capable of flight, ground, and water surface locomotion. </em><a href="http://arxiv.org/abs/2001.02320">http://arxiv.org/abs/2001.02320</a></p>
<p class="reference-item">Perez, E., Strub, F., de Vries, H., Dumoulin, V. &amp; Courville, A. (2017). <em>FiLM: Visual Reasoning with a General Conditioning Layer. </em><a href="http://arxiv.org/abs/1709.07871">http://arxiv.org/abs/1709.07871</a></p>
<p class="reference-item">Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Dabis, J., Finn, C., Gopalakrishnan, K., Hausman, K., Herzog, A., Hsu, J., Ibarz, J., Ichter, B., Irpan, A., Jackson, T., Jesmonth, S., Joshi, N.J., Julian, R., Kalashnikov, D., Kuang, Y., Leal, I., Lee, K., Levine, S., Lu, Y., Malla, U., Manjunath, D., Mordatch, I., Nachum, O., Parada, C., Peralta, J., Perez, E., Pertsch, K., Quiambao, J., Rao, K., Ryoo, M., Salazar, G., Sanketi, P., Sayed, K., Singh, J., Sontakke, S., Stone, A., Tan, C., Tran, H., Vanhoucke, V., Vega, S., Vuong, Q., Xia, F., Xiao, T., Xu, P., Xu, S., Yu, T. &amp; Zitkovich, B. (2022). <em>RT-1: Robotics Transformer for Real-World Control at Scale. </em><a href="http://arxiv.org/abs/2212.06817">http://arxiv.org/abs/2212.06817</a></p>
<p class="reference-item">Kendall, A., Hawke, J., Janz, D., Mazur, P., Reda, D., Allen, J., Lam, V., Bewley, A. &amp; Shah, A. (2018). <em>Learning to Drive in a Day. </em><a href="http://arxiv.org/abs/1807.00412">http://arxiv.org/abs/1807.00412</a></p>
<p class="reference-item">Kirsch, L. &amp; Schmidhuber, J. (2022). <em>Meta Learning Backpropagation And Improving It. </em><a href="http://arxiv.org/abs/2012.14905">http://arxiv.org/abs/2012.14905</a></p>
<p class="reference-item">Smith, L., Kostrikov, I. &amp; Levine, S. (2022). <em>A Walk in the Park: Learning to Walk in 20 Minutes With Model-Free Reinforcement Learning. </em><a href="http://arxiv.org/abs/2208.07860">http://arxiv.org/abs/2208.07860</a></p>
<p class="reference-item">Hafner, D., Pasukonis, J., Ba, J. &amp; Lillicrap, T. (2023). <em>Mastering Diverse Domains through World Models. </em><a href="http://arxiv.org/abs/2301.04104">http://arxiv.org/abs/2301.04104</a></p>
<p class="reference-item">Gozalo-Brizuela, R. &amp; Garrido-Merchan, E.C. (2023). <em>ChatGPT is not all you need. A State of the Art Review of large Generative AI models. </em><a href="http://arxiv.org/abs/2301.04655">http://arxiv.org/abs/2301.04655</a></p>
<p class="reference-item">Millidge, B., Tschantz, A. &amp; Buckley, C.L. (2020). <em>Predictive Coding Approximates Backprop along Arbitrary Computation Graphs. </em><a href="http://arxiv.org/abs/2006.04182">http://arxiv.org/abs/2006.04182</a></p>
<p class="reference-item">Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J. &amp; Lowe, R. (2022). <em>Training language models to follow instructions with human feedback. </em><a href="http://arxiv.org/abs/2203.02155">http://arxiv.org/abs/2203.02155</a></p>
<p class="reference-item">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L. &amp; Polosukhin, I. (2017). <em>Attention Is All You Need. </em><a href="http://arxiv.org/abs/1706.03762">http://arxiv.org/abs/1706.03762</a></p>
<p class="reference-item">Hafner, D., Lillicrap, T., Ba, J. &amp; Norouzi, M. (2020). <em>Dream to Control: Learning Behaviors by Latent Imagination. </em><a href="http://arxiv.org/abs/1912.01603">http://arxiv.org/abs/1912.01603</a></p>
<p class="reference-item">Hinton, G. (2022). <em>The Forward-Forward Algorithm: Some Preliminary Investigations. </em><a href="http://arxiv.org/abs/2212.13345">http://arxiv.org/abs/2212.13345</a></p>
<p class="reference-item">Solomitckii, D., Li, Q.C., Balercia, T., da Silva, C.R.C.M., Talwar, S., Andreev, S. &amp; Koucheryavy, Y. (2016). <em>Characterizing the Impact of Diffuse Scattering in Urban Millimeter-Wave Deployments. </em><a href="#">#</a></p>
<p class="reference-item">Hu, E.J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L. &amp; Chen, W. (2021). <em>LoRA: Low-Rank Adaptation of Large Language Models. </em><a href="http://arxiv.org/abs/2106.09685">http://arxiv.org/abs/2106.09685</a></p>
<p class="reference-item">Seita, D. &amp; Song, X.G.A.G.H.L.E.W.P.A.S.L.D. (Accessed: 2023). <em>Koala: A Dialogue Model for Academic Research. </em><a href="http://bair.berkeley.edu/blog/2023/04/03/koala/">http://bair.berkeley.edu/blog/2023/04/03/koala/</a></p>
<p class="reference-item">Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S., Uszkoreit, J. &amp; Houlsby, N. (2021). <em>An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. </em><a href="http://arxiv.org/abs/2010.11929">http://arxiv.org/abs/2010.11929</a></p>
<p class="reference-item">Birhane, A. &amp; McGann, M. (2024). <em>Large Models of What? Mistaking Engineering Achievements for Human Linguistic Agency. </em><a href="http://arxiv.org/abs/2407.08790">http://arxiv.org/abs/2407.08790</a></p>
<p class="reference-item">Muennighoff, N., Yang, Z., Shi, W., Li, X.L., Fei-Fei, L., Hajishirzi, H., Zettlemoyer, L., Liang, P., Candès, E. &amp; Hashimoto, T. (2025). <em>s1: Simple test-time scaling. </em><a href="http://arxiv.org/abs/2501.19393">http://arxiv.org/abs/2501.19393</a></p>
<p class="reference-item">DeepSeek-AI, , Guo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R., Zhu, Q., Ma, S., Wang, P., Bi, X., Zhang, X., Yu, X., Wu, Y., Wu, Z.F., Gou, Z., Shao, Z., Li, Z., Gao, Z., Liu, A., Xue, B., Wang, B., Wu, B., Feng, B., Lu, C., Zhao, C., Deng, C., Zhang, C., Ruan, C., Dai, D., Chen, D., Ji, D., Li, E., Lin, F., Dai, F., Luo, F., Hao, G., Chen, G., Li, G., Zhang, H., Bao, H., Xu, H., Wang, H., Ding, H., Xin, H., Gao, H., Qu, H., Li, H., Guo, J., Li, J., Wang, J., Chen, J., Yuan, J., Qiu, J., Li, J., Cai, J.L., Ni, J., Liang, J., Chen, J., Dong, K., Hu, K., Gao, K., Guan, K., Huang, K., Yu, K., Wang, L., Zhang, L., Zhao, L., Wang, L., Zhang, L., Xu, L., Xia, L., Zhang, M., Zhang, M., Tang, M., Li, M., Wang, M., Li, M., Tian, N., Huang, P., Zhang, P., Wang, Q., Chen, Q., Du, Q., Ge, R., Zhang, R., Pan, R., Wang, R., Chen, R.J., Jin, R.L., Chen, R., Lu, S., Zhou, S., Chen, S., Ye, S., Wang, S., Yu, S., Zhou, S., Pan, S., Li, S.S., Zhou, S., Wu, S., Ye, S., Yun, T., Pei, T., Sun, T., Wang, T., Zeng, W., Zhao, W., Liu, W., Liang, W., Gao, W., Yu, W., Zhang, W., Xiao, W.L., An, W., Liu, X., Wang, X., Chen, X., Nie, X., Cheng, X., Liu, X., Xie, X., Liu, X., Yang, X., Li, X., Su, X., Lin, X., Li, X.Q., Jin, X., Shen, X., Chen, X., Sun, X., Wang, X., Song, X., Zhou, X., Wang, X., Shan, X., Li, Y.K., Wang, Y.Q., Wei, Y.X., Zhang, Y., Xu, Y., Li, Y., Zhao, Y., Sun, Y., Wang, Y., Yu, Y., Zhang, Y., Shi, Y., Xiong, Y., He, Y., Piao, Y., Wang, Y., Tan, Y., Ma, Y., Liu, Y., Guo, Y., Ou, Y., Wang, Y., Gong, Y., Zou, Y., He, Y., Xiong, Y., Luo, Y., You, Y., Liu, Y., Zhou, Y., Zhu, Y.X., Xu, Y., Huang, Y., Li, Y., Zheng, Y., Zhu, Y., Ma, Y., Tang, Y., Zha, Y., Yan, Y., Ren, Z.Z., Ren, Z., Sha, Z., Fu, Z., Xu, Z., Xie, Z., Zhang, Z., Hao, Z., Ma, Z., Yan, Z., Wu, Z., Gu, Z., Zhu, Z., Liu, Z., Li, Z., Xie, Z., Song, Z., Pan, Z., Huang, Z., Xu, Z., Zhang, Z. &amp; Zhang, Z. (2025). <em>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. </em><a href="http://arxiv.org/abs/2501.12948">http://arxiv.org/abs/2501.12948</a></p>
<p class="reference-item">Zhou, C., Liu, P., Xu, P., Iyer, S., Sun, J., Mao, Y., Ma, X., Efrat, A., Yu, P., Yu, L., Zhang, S., Ghosh, G., Lewis, M., Zettlemoyer, L. &amp; Levy, O. (2023). <em>LIMA: Less Is More for Alignment. </em><a href="http://arxiv.org/abs/2305.11206">http://arxiv.org/abs/2305.11206</a></p>
<p class="reference-item">Cho, K. (2015). <em>Natural Language Understanding with Distributed Representation. </em><a href="http://arxiv.org/abs/1511.07916">http://arxiv.org/abs/1511.07916</a></p>
<p class="reference-item">Goldberg, Y. (2015). <em>A Primer on Neural Network Models for Natural Language Processing. </em><a href="http://arxiv.org/abs/1510.00726">http://arxiv.org/abs/1510.00726</a></p>
<p class="reference-item">Fein-Ashley, J. (2025). <em>The FFT Strikes Back: An Efficient Alternative to Self-Attention. </em><a href="http://arxiv.org/abs/2502.18394">http://arxiv.org/abs/2502.18394</a></p>
<p class="reference-item">Gandhi, K., Chakravarthy, A., Singh, A., Lile, N. &amp; Goodman, N.D. (2025). <em>Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs. </em><a href="http://arxiv.org/abs/2503.01307">http://arxiv.org/abs/2503.01307</a></p>
<p class="reference-item">Wilson, A.G. (2025). <em>Deep Learning is Not So Mysterious or Different. </em><a href="http://arxiv.org/abs/2503.02113">http://arxiv.org/abs/2503.02113</a></p>
<p class="reference-item">Zhu, J., Chen, X., He, K., LeCun, Y. &amp; Liu, Z. (2025). <em>Transformers without Normalization. </em><a href="http://arxiv.org/abs/2503.10622">http://arxiv.org/abs/2503.10622</a></p>
<p class="reference-item">Singh, S., Nan, Y., Wang, A., D&#x27;Souza, D., Kapoor, S., Üstün, A., Koyejo, S., Deng, Y., Longpre, S., Smith, N., Ermis, B., Fadaee, M. &amp; Hooker, S. (2025). <em>The Leaderboard Illusion. </em><a href="http://arxiv.org/abs/2504.20879">http://arxiv.org/abs/2504.20879</a></p>
<p class="reference-item">Darlow, L., Regan, C., Risi, S., Seely, J. &amp; Jones, L. (2025). <em>Continuous Thought Machines. </em><a href="http://arxiv.org/abs/2505.05522">http://arxiv.org/abs/2505.05522</a></p>
<p class="reference-item">Zhao, A., Wu, Y., Yue, Y., Wu, T., Xu, Q., Yue, Y., Lin, M., Wang, S., Wu, Q., Zheng, Z. &amp; Huang, G. (2025). <em>Absolute Zero: Reinforced Self-play Reasoning with Zero Data. </em><a href="http://arxiv.org/abs/2505.03335">http://arxiv.org/abs/2505.03335</a></p>
<p class="reference-item">Jaghouar, S., Mattern, J., Ong, J.M., Straube, J., Basra, M., Pazdera, A., Ferrante, M.D., Thaman, K., Gabriel, F., Obeid, F., Erdem, K., Keiblinger, M. &amp; Hagemann, J. (). <em>INTELLECT-2: A Reasoning Model Trained Through Globally Decentralized Reinforcement Learning. </em><a href="#">#</a></p>
<p class="reference-item">Laban, P., Hayashi, H., Zhou, Y. &amp; Neville, J. (2025). <em>LLMs Get Lost In Multi-Turn Conversation. </em><a href="http://arxiv.org/abs/2505.06120">http://arxiv.org/abs/2505.06120</a></p>
<p class="reference-item">Jha, R., Zhang, C., Shmatikov, V. &amp; Morris, J.X. (2025). <em>Harnessing the Universal Geometry of Embeddings. </em><a href="http://arxiv.org/abs/2505.12540">http://arxiv.org/abs/2505.12540</a></p></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/ml","query":{},"buildId":"-alH5WFx6uSTWWPfIdEA9","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>